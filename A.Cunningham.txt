Intel doesn't have a ton to show for its dedicated GPU efforts yet.


After much anticipation, many delays, and an anticipatory apology tour for its software quality, Intel launched its first Arc GPUs at the end of 2022. There were things to like about the A770 and A750, but buggy drivers, poor performance in older games, and relatively high power use made them difficult to recommend. They were more notable as curiosities than as consumer graphics cards.


The result, after more than two years on the market, is that Arc GPUs remain a statistical nonentity in the GPU market, according to analysts and the Steam Hardware Survey. But it was always going to take time—and probably a couple of hardware generations—for Intel to make meaningful headway against entrenched competitors.




Intel's reference design is pretty by the book, with two fans, a single 8-pin power connector, and a long heatsink and fan shroud that extends several inches beyond the end of the PCB. Andrew Cunningham




 Three DisplayPorts and one HDMI is typical for most GPUs. Andrew Cunningham
 Intel's Arc B580.Andrew Cunningham
The new Arc B580 card, the first dedicated GPU based on the new "Battlemage" architecture, launches into the exact same "sub-$300 value-for-money" graphics card segment that the A770 and A750 are already stuck in. But it's a major improvement over those cards in just about every way, and Intel has gone a long way toward fixing drivers and other issues that plagued the first Arc cards at launch. If nothing else, the B580 suggests that Intel has some staying power and that the B700-series GPUs could be genuinely exciting if Intel can get one out relatively soon.


Specs and testbed notes


Specs for the Arc B580 and B570. Credit: Intel
Ars Video
What Happens to the Developers When AI Can Code? | Ars Frontiers


The Arc B580 and Arc B570 lead the charge for the Battlemage generation. Both are based on the same GPU silicon, but the B580 has a few more execution resources, slightly higher clock speeds, a 192-bit memory bus instead of 160-bit, and 12GB of memory instead of 10GB.






Intel positions both cards as entry-level 1440p options because they have a bit more RAM than the 8GB baseline of the GeForce RTX 4060 and Radeon RX 7600. These 8GB cards are still generally fine at 1080p, but more memory does make the Arc cards feel a little more future-proof, especially since they're fast enough to actually hit 60 fps in a lot of games at 1440p.


Gaming testbed
CPU        AMD Ryzen 7 7800X3D (provided by AMD)
Motherboard        Asus ROG Crosshair X670E Hero (provided by AMD)
RAM        32GB (2x16GB) G.Skill Trident Z5 Neo (provided by AMD), running at DDR5-6000
SSD        Western Digital Black SN850 1TB (provided by Western Digital)
Power supply        EVGA Supernova 850 P6 (provided by EVGA)
CPU cooler        280 mm Corsair iCure H115i Elite Capellix AIO
Case        Lian Li O11 Air Mini
OS        Windows 11 23H2 with Core Isolation on, Memory Integrity off
Drivers        Nvidia cards: Driver 551.15
AMD RX 7600: Adrenalin 23.12.1
AMD RX 7600 XT: Pre-release driver 23.40.0.1.15
Intel Arc A770/A750: Driver 32.0.101.6319
Intel Arc B580: Pre-release driver 32.0.101.6251
Our testbed remains largely the same as it has been for a while, though we've swapped the ASRock X670E board for an Asus model. The Ryzen 7 7800X3D remains the heart of the system, with more than enough performance to avoid bottlenecking midrange and high-end GPUs.


We haven't done extensive re-testing of most older GPUs—the GeForce and Radeon numbers here are the same ones we used in the RX 7600 XT review earlier this year. We wouldn't expect new drivers to change the scores in our games much since they're mostly a bit older—we still use a mix of DirectX 11 and DirectX 12 games, including a few with and without ray-tracing effects enabled. We have re-tested the older Arc cards with recent drivers since Intel does still occasionally make changes that can have a noticeable impact on older games.


As with the Arc A-series cards, Intel emphatically recommends that resizable BAR be enabled for your motherboard to get optimal performance. This is sometimes called Smart Access Memory or SAM, depending on your board; most AMD AM4 and 8th-gen Intel Core systems should support it after a BIOS update, and newer PCs should mostly have it on by default. Our test system had it enabled for the B580 and for all the other GPUs we tested.






Performance and power


























As a competitor to the RTX 4060, the Arc B580 is actually pretty appealing, whether you're talking about 1080p or 1440p, in games with ray-tracing on or off. Even older DirectX 11 titles in our suite, like Grand Theft Auto V and Assassin's Creed Odyssey, don't seem to take the same performance hit as they did on older Arc cards.


Intel is essentially making a slightly stronger version of the argument that AMD has been trying to make with the RX 7600. AMD's cards always come with the caveat of significantly worse performance in games with heavy ray-tracing effects, but the performance hit for Intel cards in ray-traced games looks a lot more like Nvidia's than AMD's. Playable ray-traced 1080p is well within reach for the Intel card, and in both Cyberpunk 2077 and Returnal, its performance came closer to the 8GB 4060 Ti's.














The 12GB of RAM is also enough to put more space between the B580 and the 8GB versions of the 4060 and 7600. Forza Horizon 5 performs significantly better at 1440p on cards with more memory, like the B580 and the 16GB RX 7600 XT, and it's a safe bet that the 8GB limit will become more of a factor for high-end games at higher resolutions as the years go on.


We experienced just one performance anomaly in our testing. Forza Horizon 5 actually runs a bit worse with XeSS enabled, with a smooth average frame rate but frequent stutters that make it less playable overall (though it's worth noting that Forza Horizon 5 never benefits much from upscaling algorithms on any GPUs we've tested, for whatever reason). Intel also alerted us to a possible issue with Cyberpunk 2077 when enabling ray-tracing but recommended a workaround that involved pressing F1 to reset the game's settings; the benchmark ran fine on our testbed.








GPU power consumption numbers under load. Credit: Andrew Cunningham
Power consumption is another place where the Battlemage GPU plays a lot of catch-up with Nvidia. With the caveat that software-measured power usage numbers like ours are less accurate than numbers captured with hardware tools, it looks like the B580's power consumption, when fully loaded, consumes somewhere between 120 and 130 W in Hitman and Borderlands. This is a tad higher than the 4060, but it's lower than either Radeon RX 7600.


It's not the top of the class, but looking at the A750's power consumption shows how far Intel has come—the B580 beats the A750's performance every single time while consuming about 60 W less power.


A strong contender, a late arrival


The Intel Arc B580. Credit: Andrew Cunningham
Intel is explicitly targeting Nvidia's GeForce RTX 4060 with the Arc B580, a role it fills well for a low starting price. But the B580 is perhaps more damaging to AMD, which positions both of its 7600-series cards (and the remaining 6600-series stuff that's hanging around) in the same cheaper-than-Nvidia-with-caveats niche.


In fact, I'd probably recommend the B580 to a budget GPU buyer over any of the Radeon RX 7600 cards at this point. For the same street price as the RX 7600, Intel is providing better performance in most games and much better performance in ray-traced games. The 16GB 7600 XT has more RAM, but it's $90 to $100 more expensive, and a 12GB card is still reasonably future-proof and decent at 1440p.


All of that said, Intel is putting out a great competitor to the RTX 4060 and RX 7600 a year and a half after those cards both launched—and within just a few months of a possible RTX 5060. Intel is selling mid-2023's midrange GPU performance in late 2024. There are actually good arguments for building a budget gaming PC right this minute, before potential Trump-administration tariffs can affect prices or supply chains, but assuming the tech industry can maintain its normal patterns, it would be smartest to wait and see what Nvidia does next.






Nvidia also has some important structural benefits. DLSS upscaling support is nearly ubiquitous in high-end games, Nvidia's drivers are more battle-tested, and it's extremely unlikely that Nvidia will decide to pull out of the GPU market and stop driver development any time soon (Intel has published a roadmap encompassing multiple GPU generations, which is reassuring, but the company's recent financial distress has seen it shed several money-losing hobby projects).


If there's a saving grace for Intel and the B580, it's that Nvidia has signaled, both through its statements and its behavior, that it's mostly uninterested in aggressively lowering GPU prices, either over time (Nvidia GPUs tend not to stray far from MSRP, barring supply issues) or between generations. An RTX 5060 is highly unlikely to be cheaper than a 4060 and could easily be more expensive. Depending on how good a hypothetical RTX 5060 is, Intel still has a lot of room to offer good performance for the price in a $200-to-$250-ish GPU market that doesn't get a ton of attention.


The other issue for Intel is that for a second straight GPU generation, the company is launching late with a part that is forced by its performance to play in a budget-oriented, low-margin area of the GPU market. I don't think I'm expecting a 4090 or 5090-killer out of Intel any time soon, but based on the B580, I'm at least a little optimistic that Intel can offer a B700-series card that can credibly compete with the likes of Nvidia's 4070-series or AMD's 7800 XT and 7900 GRE. Performance-wise, that's the current sweet spot of the GPU market, but you'll spend more than you would on a PS5 to buy most of those cards. If Intel can shake up that part of the business, it could help put Arc on the map.


The good
Solid midrange 1080p and 1440p performance at a good starting price
More RAM than the competition
Much-improved power efficiency compared to Arc A-series GPUs
Unlike the A-series, we noticed no outliers where performance was disproportionately bad
Simple, clean-looking reference design from Intel
The bad
Competing with cards that launched a year and a half ago
New Nvidia and AMD competitors are likely within a few months
Intel still can't compete at the high end of the GPU market, or even the medium-high end
The ugly
So far, Arc cards have not been successful enough to guarantee their long-term existence
The macOS 15.2 update that was released earlier today came with a handful of new features, plus something unexpected: an apparently accidental reference to the upcoming M4 MacBook Airs. MacRumors reports that the "Mac16,12" and "Mac16,13" model identifiers reference 13- and 15-inch models of the M4 Air and that both are coming in 2025.


That a MacBook Air refresh is planned for next year isn't much of a surprise at this point—in reporting that pretty much nailed the details of the first M4 Macs, Bloomberg's Mark Gurman has said that the Air, the Mac Studio, and the Mac Pro are all slated for updates throughout 2025.


But a reference in the current release of macOS could point to a launch sooner rather than later; the M4 Mac mini was referenced in a macOS update in mid-September around a month and a half before it was released. The M3 Airs came out in March this year, but Apple has been known to put out new Macs as early as January in recent years.


The M4 isn't a gigantic update over the M3—we tested its performance in the M4 iMac, though a passively cooled MacBook Air version would likely be a bit slower at heavier workloads—but the fully enabled version does come with two extra CPU cores and some nice quality-of-life updates. Those updates include Thunderbolt 5 ports and support for a total of three displays (two external and the built-in screen), up from a total of two for the M1, M2, and M3 MacBook Airs.


Ars Video
How The Callisto Protocol's Gameplay Was Perfected Months Before Release


We didn't get M4 MacBook Airs in November, but Apple did "update" the M2 and M3 versions from 8GB to 16GB of RAM without increasing their prices. The RAM increase will be useful for all kinds of things, though it could be a harbinger of increased memory requirements for upcoming Apple Intelligence features.
This expensive all-in-one's unique screen was the only thing going for it.


Andrew Cunningham – Dec 6, 2024 1:38 PM |  93


RIP to Microsoft's Surface Studio all-in-one desktop. Credit: Microsoft


Microsoft has formally discontinued its Surface Studio all-in-one desktop, the company confirmed to Windows Central, a $4,300 touchscreen PC that the company updated with new components twice in the space of eight years. Windows Central reports that there are currently no plans for a follow-up to the Surface Studio and that a Surface Studio 3 may have been among the casualties of cutbacks to Microsoft's Surface lineup.


Like the Surface Laptop Studio, the desktop's claim to fame was a unique hinge design for its screen, which could reposition it to make it easier to draw on with the Surface Pen. But the desktop's high cost and its perennially outdated internal components made it a less appealing machine than it could have been.


Ars Video
How The Callisto Protocol's Gameplay Was Perfected Months Before Release


The first version of the Surface Studio desktop debuted in late 2016. As the company's first desktop PC, it used the same basic design as the current version and was praised for its high-quality screen and unique hinge. But the first Surface Studio of the machine had some of the same issues that the desktop would always have: a high starting price and relatively outdated and underpowered components compared to other desktop systems.






The longest-lived Studio desktop was the Surface Studio 2, which was released in 2018 and wasn't replaced until a revised Surface Studio 2+ was announced in late 2022. It used an even higher-quality display panel, but it still used previous-generation internal components. This might not have been so egregious if Microsoft had updated it more consistently, but this model went untouched for so long that Microsoft had to lower Windows 11's system requirements specifically to cover the Studio 2 so that the company wouldn't be ending support for a PC that it was still actively selling.


The Studio 2+ was the desktop's last hurrah, and despite jumping two GPU generations and four CPU generations, it still didn't use the latest components available at the time. Again, more consistent updates like the ones Microsoft provides for the Surface Pro and Surface Laptop could have made this less of a problem, but the Studio 2+ once again sat untouched for two years after being updated.


The Studio desktop's unique screen and hinge endeared it to some artists, and for those users, there's no immediately obvious replacement for this machine. But the all-in-one's high price and its specs always made it a hard sell for anyone else. A lack of wide appeal usually leads to mediocre sales, and mediocre sales usually lead to discontinued products. So it goes.
Nvidia partners leak next-gen RTX 50-series GPUs, including a 32GB 5090
The 5080, 5070 Ti, 5070, and a 5090D variant for China were also listed.


Andrew Cunningham – Dec 17, 2024 1:16 PM |  148
A large Nvidia logo at a conference hall
Credit: Getty Images | NurPhoto


Rumors have suggested that Nvidia will be taking the wraps off of some next-generation RTX 50-series graphics cards at CES in January. And as we get closer to that date, Nvidia's partners and some of the PC makers have begun to inadvertently leak details of the cards.


According to recent leaks from both Zotac and Acer, it looks like Nvidia is planning to announce four new GPUs next month, all at the high end of its lineup: The RTX 5090, RTX 5080, RTX 5070 Ti, and RTX 5070 were all briefly listed on Zotac's website, as spotted by VideoCardz. There's also an RTX 5090D variant for the Chinese market, which will presumably have its specs tweaked to conform with current US export restrictions on high-performance GPUs.


Though the website leak didn't confirm many specs, it did list the RTX 5090 as including 32GB of GDDR7, an upgrade from the 4090's 24GB of GDDR6X. An Acer spec sheet for new Predator Orion desktops also lists 32GB of GDDR7 for the 4090, as well as 16GB of GDDR7 for the RTX 5080. This is the same amount of RAM included with the RTX 4080 and 4080 Super.


Ars Video
How Scientists Respond to Science Deniers


The 5090 will be a big deal when it launches because no graphics card released since October 2022 has come close to beating the 4090’s performance. Nvidia’s early 2024 Super refresh for some 40-series cards didn’t include a 4090 Super, and AMD’s flagship RX 7900 XTX card is more comfortable competing with the likes of the 4080 and 4080 Super. The 5090 isn't a card that most people are going to buy, but for the performance-obsessed, it's the first high-end performance upgrade the GPU market has seen in more than two years.






But we'd also expect the 5090 to be more expensive than the $1,599 MSRP of the RTX 4090. The 5090's GB202 GPU die is said to be physically larger than the AD102 GPU die used in the 4090, despite using a more advanced TSMC manufacturing process. Nvidia and its partners have also had problems keeping the RTX 4090 available at or anywhere close to its $1,599 MSRP in the first place. And while AMD and Intel do a good job of competing with Nvidia's other product tiers, neither company has released anything that can compete with the 4090's performance, to say nothing of the 5090.


A price hike would also be consistent with statements from Nvidia CEO Jensen Huang, who has said that chips getting less expensive over time is "a story of the past" (though obviously, as someone with a vested interest in keeping prices high, Huang may not be an impartial source of information on this topic).


The new leaks didn't confirm much one way or the other about the 5070 Ti or 5070, though other leaks have suggested that the cards will include 16GB and 12GB of GDDR7 memory, respectively. This is in line with the memory capacities of the current 4070 Ti Super and 4070 Super.


Missing from the leak were any planned 5060-series cards for midrange gaming PCs. Nvidia usually starts at the top of its stack and works downward, so that's not too surprising. Hopefully we'll see some kind of midrange refresh from Nvidia later in the spring or summer of 2025.
Join us today for Ars Live: How Asahi Linux ports open software to Apple’s hardware
Join us 3:30 pm ET Wednesday to unpack the effort to run Linux on Apple Silicon.


Andrew Cunningham – Dec 4, 2024 11:15 AM |  72


Slowly but surely, the Asahi Linux team is getting Linux up and running on Apple Silicon Macs. Credit: Apple/Asahi Linux


One of the key differences between Apple's Macs and the iPhone and iPad is that the Mac can still boot and run non-Apple operating systems. This is a feature that Apple specifically built for the Mac, one of many features meant to ease the transition from Intel's chips to Apple's own silicon.


The problem, at least at first, was that alternate operating systems like Windows and Linux didn't work natively with Apple's hardware, not least because of missing drivers for basic things like USB ports, GPUs, and power management. Enter the Asahi Linux project, a community-driven effort to make open-source software run on Apple's hardware.


In just a few years, the team has taken Linux on Apple Silicon from "basically bootable" to "plays native Windows games and sounds great doing it." And the team's ultimate goal is to contribute enough code upstream that you no longer need a Linux distribution just for Apple Silicon Macs.


On December 4 at 3:30 pm Eastern (12:30 pm Pacific), Ars Technica Senior Technology Reporter Andrew Cunningham will host a livestreamed YouTube conversation with Asahi Linux Project Lead Hector Martin and Graphics Lead Alyssa Rosenzweig that will cover the project's genesis and its progress, as well as what the future holds.
Intel’s second-generation Arc B580 GPU beats Nvidia’s RTX 4060 for $249
Intel's dedicated GPUs are back for another round, and they're aiming for 1440p.


Andrew Cunningham – Dec 3, 2024 3:56 PM |  182


Intel's next-gen B-series dedicated GPUs are launching soon, with the decidedly midrange B500-series cards out in front. Credit: Intel


Turnover at the top of the company isn't stopping Intel from launching new products: Today the company is announcing the first of its next-generation B-series Intel Arc GPUs, the Arc B580 and Arc B570.


Both are decidedly midrange graphics cards that will compete with the likes of Nvidia's GeForce RTX 4060 and AMD's RX 7600 series, but Intel is pricing them competitively: $249 for a B580 with 12GB of RAM and $219 for a B570 with 10GB of RAM. The B580 launches on December 13, while the B570 won't be available until January 16.


The two cards are Intel's first dedicated GPUs based on its next-generation "Battlemage" architecture, a successor to the "Alchemist" architecture used in the A-series cards. Intel's Core Ultra 200 laptop processors were its first products to ship with Battlemage, though they used an integrated version with fewer of Intel's Xe cores and no dedicated memory. Both B-series GPUs use silicon manufactured on a 5 nm TSMC process, an upgrade from the 6 nm process used for the A-series; as of this writing, no integrated or dedicated Arc GPUs have been manufactured by one of Intel's factories.


Both cards use a single 8-pin power connector, at least in Intel's reference design; Intel is offering a first-party limited-edition version of the B580, while it looks like partners like Asus, ASRock, Gunnir, Maxsun, Onix, and Sparkle will be responsible for the B570.






 The Arc B580 will be available in a limited-edition design from Intel.Intel
 Intel's partners will handle the other cards, including all versions of the B570. The B580 and B570 will launch for $249 and $219, respectively.Intel
Compared to the original Arc GPUs, both Battlemage cards should benefit from the work Intel has put into its graphics drivers over the last two years—a combination of performance improvements plus translation layers for older versions of DirectX have all improved Arc's performance quite a bit in older games since late 2022. Hopefully buyers won't need to wait months or years to get good performance out of the Battlemage cards.


Ars Video
How The Callisto Protocol's Team Designed Its Terrifying, Immersive Audio


The new cards also come with XeSS 2, the next-generation version of Intel's upscaling technology (analogous to DLSS for Nvidia cards and FSR for AMD's). Like DLSS 3 and FSR 3, one of XeSS 2's main additions is a frame-generation feature that can interpolate additional frames to insert between the frames that are actually being rendered by the graphics card. These kinds of technologies tend to work best when the cards are already running at a reasonably high frame rate, but when they're working well, they can lead to smoother-looking gameplay. A related technology, Xe Low Latency, aims to reduce the increase in latency that comes with frame-generation technologies, similar to Nvidia's Reflex and AMD's Anti-Lag.






Targeting 8GB GPUs
Both the Nvidia and AMD cards in this sub-$300 price range top out at 8GB of RAM, something Intel is targeting with its marketing for the new cards. When Intel says the B580 performs about 10 percent better on average than the RTX 4060, it's running those tests at 1440p, a resolution where games will begin running into that 8GB RAM limit more regularly than they will at 1080p.


Nvidia's cheapest current-gen card with more than 8GB of RAM is the 16GB version of the 4060 Ti (roughly $450 as of this writing), while AMD offers a 16GB version of the less-powerful RX 7600 XT for around $320. The Intel cards offer less RAM than this but undercut them significantly on price while still providing more than 8GB.




Intel says the B580 is about 10 percent faster than the RTX 4060, at least at 1440p. Intel




 The B580 is also about 24 percent faster than the Arc A750 at 1440p, though we don't know whether to expect a B750 or B770. Intel
 Intel is aiming for performance-per-dollar here, particularly when it comes to ray-traced performance.Intel
Intel's promotional slides point out that this RAM bump is particularly relevant when ray tracing is turned on and can make the difference between the Arc card running behind the RTX 4060 and running ahead of it. (Intel also points out that its midrange ray-tracing performance is a significant step up over AMD's.)


Generation over generation, Intel claims that the B580 is around 24 percent faster on average than the last-generation Arc A750, another 8GB card. Intel didn't provide performance comparisons to the 16GB Arc A770 card, although we'll compare the two cards in our review.


Intel isn't talking about any other B-series GPUs today, but launching the 500-series cards first implies that we could see B700-series GPUs at some point next year that attempt to compete with higher-end Nvidia cards like the 4060 Ti or 4070. That said, Nvidia is expected to begin launching the RTX 5000 series early next year, so Nvidia's midrange lineup is a bit of a moving target at the moment.